{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML4SCI/DeepLearnHackathon/blob/main/HiggsBosonClassificationChallenge/higgs_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9URMW3ZkrBGi"
      },
      "source": [
        "# Higgs Classification Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4kV4R6SDR8X"
      },
      "source": [
        "**Introduction:** \n",
        "\n",
        "High-energy collisions at the Large Hadron Collider (LHC) produce particles that interact with particle detectors. One important task is to classify different types of collisions based on their physics content, allowing physicists to find patterns in the data and to potentially unravel new discoveries.\n",
        "\n",
        "The discovery of the Higgs boson by CMS and ATLAS Collaborations was announced at CERN in 2012. In this challenge, we will use machine learning to classify events containing Higgs bosons from the background events which do not contain Higgs bosons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAJnE-4uANmP"
      },
      "source": [
        "**Dataset:** \n",
        "\n",
        "The dataset consists of a total of 11 million labeled samples of Higgs and background events produced by Monte Carlo simulations. Each sample consists of 28 features. The first 21 features are kinematic properties of the events. The last seven are functions of the first 21. The data labels are 1 for signal (an event with Higgs bosons) and 0 for background (an event without Higgs bosons).\n",
        "\n",
        "The dataset is hosted by the Center for Machine Learning and Intelligent Systems at University of California, Irvine. The dataset can be found on the [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/datasets/HIGGS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "\n",
        "* `.ipynb` (and a PDF version of it with outputs showing your results) file showing your solution, including your study of the data, final model structure, hyperparameters and the wat the model was trained that yielded the best possible performance.\n",
        "* Final model accuracy (training and validation) ROC curve and AUC score, as well as an additional plot (e.g. precision-recall curves, confusion matrix) which further showcases the performance of your model.\n",
        "* Your trained model containing the model architecture and its trained weights (HDF5 file, .pb file, .pt file, etc.). Also show in your notebooks how to load and use your model.\n",
        "\n",
        "**Note: You are free to use the ML framework of your choice.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myu16dmzSBmo"
      },
      "source": [
        "## Download the Dataset\n",
        "\n",
        "If you are working in Colab, to not have to re-download the data all the time, you can mount your Google Drive and download/fetch the data to/from there ([link for more info](https://towardsdatascience.com/different-ways-to-connect-google-drive-to-a-google-colab-notebook-pt-1-de03433d2f7a))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrM-WOaxRWsP"
      },
      "outputs": [],
      "source": [
        "!wget https://cernbox.cern.ch/s/yxNp4natupdVJ30/download /content/HIGGS.csv.gz\n",
        "!gzip -d /content/HIGGS.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"/content/\" # Put here in what directory your data lives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUE2QepFVwEq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GDeVfB04Qe4"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTnbxdjkUp73"
      },
      "source": [
        "* Two classes: Higgs event and background event\n",
        "* As loaded below, the first column is the label (1 = Higgs event, 0 = background event), and the rest of the columns are all of our inputs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoRPhH9dNmCy"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./HIGGS.csv', header=None)\n",
        "X = data.iloc[:,1:]\n",
        "y = data.iloc[:,0]\n",
        "#X = X.to_numpy(dtype=float) #Convert pandas dataframe to numpy array (optional)\n",
        "#y = y.to_numpy(dtype=int)   #Convert pandas dataframe to numpy array (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring Tarining / Validation / Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50-8I-fj8jC7"
      },
      "outputs": [],
      "source": [
        "X_train, X_val1, y_train, y_val1 = train_test_split(\n",
        "    X, \n",
        "    y, \n",
        "    test_size=0.0909090909, \n",
        "    random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_val1, \n",
        "    y_val1, \n",
        "    test_size=0.5, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PexwSVQ34M_l"
      },
      "source": [
        "## Task 1:\n",
        "\n",
        "*Data: Training data*\n",
        "\n",
        "Explore, visualize and analyze the data found in the training dataset.\n",
        "\n",
        "Detailed information on what each feature can be found in *Attribute Information* section on the [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/datasets/HIGGS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This list of feature names might be useful...\n",
        "\n",
        "names = [\n",
        "    \"lepton pT\", \"lepton eta\", \"lepton phi\", \n",
        "    \"missing energy magnitude\",\"missing energy phi\", \n",
        "    \"jet 1 pt\", \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\",\n",
        "    \"jet 2 pt\", \"jet 2 eta\",\"jet 2 phi\", \"jet 2 b-tag\", \n",
        "    \"jet 3 pt\", \"jet 3 eta\", \"jet 3 phi\", \"jet 3 b-tag\", \n",
        "    \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\",\n",
        "    \"m_jj\", \"m_jjj\", \"m_lv\", \"m_jlv\", \"m_bb\", \"m_wbb\", \"m_wwbb\" # Derived quantities\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJaFEoGApL5"
      },
      "source": [
        "## Task 2:\n",
        "\n",
        "*Data: Training and validation data*\n",
        "\n",
        "Train a model by fitting it to the training data. Use at least one metric such as `roc_auc_score`, `accuracy`, etc. to analyze the model's performance on the validation data. Using that performance metric, optimize or improve your model. It should be clear from your notebook how you perform this optimization and you should explain your thinking clearly.\n",
        "\n",
        "As you work on your model, you may use a subset of the actual dataset to haisten your tests. However, for final submission, you must use the full test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use your framework of choice. \n",
        "\n",
        "# Define your model here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train your model here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3t0NHGQa-yb"
      },
      "source": [
        "## Task 3: \n",
        "\n",
        "*Data: Testing data*\n",
        "\n",
        "Without having done any optimization using the testing data set, analyze the performance of the model on the testing data. Your analysis should include the AUC score, a ROC curve plot, and at least one other plot of your choice such as precision-recall curves, confusion matrix, etc. Try to get your model to perform with AUC > 90%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
