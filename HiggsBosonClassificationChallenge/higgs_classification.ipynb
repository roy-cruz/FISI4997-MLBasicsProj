{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML4SCI/DeepLearnHackathon/blob/main/HiggsBosonClassificationChallenge/higgs_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9URMW3ZkrBGi"
      },
      "source": [
        "# Higgs Classification Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4kV4R6SDR8X"
      },
      "source": [
        "**Introduction:** \n",
        "\n",
        "High-energy collisions at the Large Hadron Collider (LHC) produce particles that interact with particle detectors. One important task is to classify different types of collisions based on their physics content, allowing physicists to find patterns in the data and to potentially unravel new discoveries.\n",
        "\n",
        "The discovery of the Higgs boson by CMS and ATLAS Collaborations was announced at CERN in 2012. In this challenge, we will use machine learning to classify events containing Higgs bosons from the background events which do not contain Higgs bosons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAJnE-4uANmP"
      },
      "source": [
        "**Dataset:** \n",
        "\n",
        "The dataset consists of a total of 11 million labeled samples of Higgs and background events produced by Monte Carlo simulations. Each sample consists of 28 features. The first 21 features are kinematic properties of the events. The last seven are functions of the first 21. The data labels are 1 for signal (an event with Higgs bosons) and 0 for background (an event without Higgs bosons).\n",
        "\n",
        "The dataset is hosted by the Center for Machine Learning and Intelligent Systems at University of California, Irvine. The dataset can be found on the [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/datasets/HIGGS)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "\n",
        "* PDF and .ipynb file showing your solution.\n",
        "* Final model accuracy (training and validation) ROC curve and AUC score, as well as an additional plot (e.g. precision-recall curves, confusion matrix) which further showcases the performance of your model \n",
        "* Final model structure, parameters and hyper-parameters yielding the best possible performance.\n",
        "* Actual trained model containing the model architecture adn its trained weights (HDF5 file, .pb file, .pt file, etc). Also show in your notebooks how to load and use your model.\n",
        "\n",
        "**Note: You are free to use the ML framework of your choice.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myu16dmzSBmo"
      },
      "source": [
        "## Downloading the Dataset\n",
        "If you are having problems with this part in Colab, you can also download the file manually and put it in your Google Drive. You can then [connect your Google Drive to Colab](https://towardsdatascience.com/different-ways-to-connect-google-drive-to-a-google-colab-notebook-pt-1-de03433d2f7a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrM-WOaxRWsP"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\n",
        "!gzip -d HIGGS.csv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUE2QepFVwEq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GDeVfB04Qe4"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTnbxdjkUp73"
      },
      "source": [
        "* Two classes: Higgs event and background event\n",
        "* As loaded below, the first column is the label (1 = Higgs event, 0 = background event), and the rest of the oclumns are all of our inputs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoRPhH9dNmCy"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./HIGGS.csv', header=None)\n",
        "X = data.iloc[:,1:]\n",
        "y = data.iloc[:,0]\n",
        "#X = X.to_numpy(dtype=float) #Convert pandas dataframe to numpy array (optional)\n",
        "#y = y.to_numpy(dtype=int)   #Convert pandas dataframe to numpy array (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring Tarining / Validation / Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50-8I-fj8jC7"
      },
      "outputs": [],
      "source": [
        "X_train, X_val1, y_train, y_val1 = train_test_split(\n",
        "    X, \n",
        "    y, \n",
        "    test_size=0.0909090909, \n",
        "    random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_val1, \n",
        "    y_val1, \n",
        "    test_size=0.5, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PexwSVQ34M_l"
      },
      "source": [
        "## Task 1:\n",
        "\n",
        "Data: `X_train`\n",
        "\n",
        "Generate histograms of the different variables in `X_train` with proper axis labels and titles.\n",
        "\n",
        "Detailed information on what each feature column is can be found in *Attribute Information* section on the [UCI Machine learning Repository](https://archive.ics.uci.edu/ml/datasets/HIGGS). For further information, refer to the [paper](https://www.nature.com/articles/ncomms5308) by Baldi et. al\n",
        "\n",
        "The following may be helpful:\n",
        "\n",
        "`names = [\"lepton pT\", \"lepton eta\", \"lepton phi\", \"missing energy magnitude\",` <br>\n",
        "`\"missing energy phi\", \"jet 1 pt\", \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\",` <br>\n",
        "`\"jet 2 pt\", \"jet 2 eta\",\"jet 2 phi\", \"jet 2 b-tag\", \"jet 3 pt\", \"jet 3 eta\",` <br>\n",
        "`\"jet 3 phi\", \"jet 3 b-tag\", \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\",`<br>` \"m_jj\", \"m_jjj\", \"m_lv\", \"m_jlv\", \"m_bb\", \"m_wbb\", \"m_wwbb\"]`\n",
        "\n",
        "`for index, name in enumerate(names):`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJaFEoGApL5"
      },
      "source": [
        "## Task 2:\n",
        "\n",
        "Data: `X_train`, `y_train`, `X_val`, `y_val`\n",
        "\n",
        "Train a model by fitting it to the training data. Use at least one metric such as roc_auc_score, accuracy, etc. to analyze the model's performance on the validation data. Using that performance metric, optimize or improve your model. It should be clear from your notebook how you perform this optimization.\n",
        "\n",
        "As you work on your model, you may use a subset of the actual dataset to haisten your tests. However, for final submission, you must use the full test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3t0NHGQa-yb"
      },
      "source": [
        "## Task 3:\n",
        "\n",
        "Data: Testing data\n",
        "\n",
        "Without having done any optimization using the testing data set, analyze the performance of the model on the testing data. You analysis should include the AUC score, a ROC curve plot, and at least one other plot of your choice such as precision-recall curves, confusion matrix, etc.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
